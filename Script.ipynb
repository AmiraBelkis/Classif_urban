{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Script.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmiraBelkis/Classif_urban/blob/main/Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "9uaznsduWyN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uploading my own dataset"
      ],
      "metadata": {
        "id": "K-Qbhd42Ff3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#importing from github\n",
        "!git clone https://github.com/AmiraBelkis/Classif_urban.git\n",
        "import sys\n",
        "sys.path.append('/content/Classif_urban')\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yh-g8sqyCCh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "os.chdir('/content/Classif_urban/train/images')\n",
        "os.chdir('/content/Classif_urban/train/masks')\n",
        "imgs   = os.listdir('/content/Classif_urban/train/images')\n",
        "masks = os.listdir('/content/Classif_urban/train/masks')\n",
        "\n",
        "imgs.sort()\n",
        "masks.sort()\n",
        "print(imgs)\n",
        "print(masks)"
      ],
      "metadata": {
        "id": "btI_-CTCegUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.zeros((9, 28,28,1), dtype=np.float32)\n",
        "X = np.zeros((9,224, 224, 1), dtype=np.float32)\n",
        "n = 0\n",
        "for file in imgs:\n",
        "  print(file)\n",
        "  #index = img.index(file)\n",
        "  dir_img = os.path.join('/content/Classif_urban/train/images', file)\n",
        "  img = Image.open(dir_img)\n",
        "  img = img.resize((224, 224))\n",
        "  img = np.reshape(img.convert('L'), (224,224,1)) \n",
        "  X[n] = img\n",
        "  n = n+1\n",
        "n = 0\n",
        "\"\"\"\n",
        "for mask in masks:\n",
        "  #mask = masks[index]\n",
        "  dir_mask = os.path.join('/content/Classif_urban/train/masks', mask)\n",
        "  mask_img = cv2.imread(dir_mask)\n",
        "  #mask_img = (mask_img!=2)*1.0  \n",
        "  mask_img_ = cv2.resize(mask_img, (28, 28))\n",
        "  #mask_img = 1.0*(mask_img_[:,:,0]>0.2)\n",
        "  #mask_img = mask_img_[:,:,0]\n",
        "  y[n] = mask_img_\n",
        "  n = n+1\"\"\"\n",
        "for file in masks:\n",
        "  print(file)\n",
        "  #index = img.index(file)\n",
        "  dir_img = os.path.join('/content/Classif_urban/train/masks', file)\n",
        "  img = Image.open(dir_img)\n",
        "  img = img.resize((28, 28))\n",
        "  img = np.reshape(img.convert('L'), (28,28,1)) \n",
        "  y[n] = img\n",
        "  n = n+1"
      ],
      "metadata": {
        "id": "uACsfbbPiN-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[1])\n",
        "print(type(y[1]))\n",
        "print(y[1].shape)"
      ],
      "metadata": {
        "id": "TO9PA-_-UVMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying our training set\n",
        "from matplotlib import pyplot as plt\n",
        "for i in range(0,2):\n",
        "  im = X[i,:,:,0]\n",
        "  mask = y[i,:,:,0]\n",
        "  plt.imshow(im, interpolation='nearest')\n",
        "  plt.show()\n",
        "  plt.imshow(mask, interpolation='nearest')\n",
        "  plt.show()\n",
        "  "
      ],
      "metadata": {
        "id": "r_SHehFRLmeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras \n",
        "import tensorflow.keras\n",
        "print(\"keras \",keras.__version__)\n",
        "print(\"tensorflow.keras \",tensorflow.keras.__version__)\n",
        "print(\"tensorflow\",tensorflow.__version__)\n",
        "!pip install segmentation_models\n",
        "import segmentation_models as sm\n",
        "print(\"segmentation_models \",sm.__version__)\n",
        "from segmentation_models import Unet\n",
        "from segmentation_models.backbones import get_preprocessing\n",
        "from segmentation_models.losses import bce_jaccard_loss\n",
        "from segmentation_models.metrics import iou_score"
      ],
      "metadata": {
        "id": "Rnr4Jn0prj8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#!pip install git+https://github.com/qubvel/segmentation_models\n",
        "!pip install segmentation_models\n",
        "!git clone https://github.com/qubvel/segmentation_models.git\n",
        "!pip install keras-segmentation\n",
        "!pip install tensorflow==1.14\n",
        "!pip install keras==2.2.4\n",
        "!pip install segmentation-models==0.1.2\n",
        "!pip install segmentation_models\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from keras.models import model_from_json\n",
        "\n",
        "from keras.layers import Input, Conv2D, Reshape\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "from segmentation_models import Unet\n",
        "from segmentation_models.backbones import get_preprocessing\n",
        "from segmentation_models.losses import bce_jaccard_loss\n",
        "from segmentation_models.metrics import iou_score"
      ],
      "metadata": {
        "id": "b1yKrBbHlHZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = get_preprocessing(BACKBONE)\n",
        "X_train = preprocess_input(X_train)\n",
        "X_test = preprocess_input(X_test)"
      ],
      "metadata": {
        "id": "yXgvfDsWmDBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Reshape\n",
        "N = X_train.shape[-1]\n",
        "base_model = Unet(backbone_name='resnet34', encoder_weights='imagenet')\n",
        "\n",
        "input_base_model = Input(shape=(224, 224, N))\n",
        "\n",
        "l1 = Conv2D(3, (1, 1))(inp)\n",
        "\n",
        "out = base_model(l1)\n",
        "\n",
        "x1 = Conv2D(10, kernel_size =3,strides=2,padding = \"same\", activation=\"relu\")(out)\n",
        "x1 =layers.BatchNormalization()\n",
        "\n",
        "x2= Conv2D(10, kernel_size=3,strides=2,padding = \"same\", activation=\"relu\")(x1)\n",
        "x2 =layers.BatchNormalization()\n",
        "\n",
        "x3 = Conv2D(10, kernel_size=3,strides=2,padding = \"same\", activation=\"relu\")(x2)\n",
        "x3 =layers.BatchNormalization()\n",
        "\n",
        "x4 = Conv2D(1, kernel_size=2,strides=2,padding = \"same\", activation=\"relu\")(x3)\n",
        "\n",
        "x_out = Reshape((28,28))(x4)\n",
        "\n",
        "model = Model(input_base_model, x_out, name=base_model.name)"
      ],
      "metadata": {
        "id": "DiRt7inJmbxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient(y_true, y_pred):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "    return numerator / (denominator + tf.keras.backend.epsilon())\n",
        "\n",
        "def loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - tf.log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())\n",
        "\n",
        "model.compile(optimizer='sgd', loss=loss, metrics=[dice_coefficient])\n",
        "\n",
        "model.fit(X_train,y_train,batch_size=32,epochs=30,validation_data=(X_test, y_test))\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "1PW16n9_GQe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "id": "oLD4CFxoGeE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_pred = model.predict(X_train)\n",
        "testing_pred = model.predict(X_test)\n",
        "\n",
        "def prediction(X, y, pred, k=None):\n",
        "    if (k  == None):\n",
        "        k = np.random.randint(0, len(X))\n",
        "\n",
        "    has_mask = y[k].max() > 0\n",
        "\n",
        "    figure, j = plt.subplots(1, 3, figsize=(20, 20))\n",
        "    j[0].imshow(X[k, ..., 0])\n",
        "    if has_mask:\n",
        "        j[0].contour(y[i].squeeze())\n",
        "    k[1].imshow(y[i].squeeze())\n",
        "    k[2].imshow(pred[i].squeeze())\n",
        "    if has_mask:\n",
        "        k[2].contour(preds[i].squeeze())"
      ],
      "metadata": {
        "id": "dlLZsr1cGpUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transflow exemple code"
      ],
      "metadata": {
        "id": "VXmf9hsTHFxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "18tGNXgR7PjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, Input, MaxPooling2D, Dropout, concatenate, UpSampling2D\n",
        "\n",
        "\n",
        "def Unet(num_class, image_size):\n",
        "\n",
        "    inputs = Input(shape=[image_size, image_size, 1])\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same')(conv9)\n",
        "    conv10 = Conv2D(num_class, 1, activation = 'sigmoid')(conv9)\n",
        "    model = Model(inputs = inputs, outputs = conv10)\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    return model\n",
        "\"\"\"\n",
        "----------------------------------------------\n",
        "\"\"\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "model = Unet(1, image_size=224)\n",
        "trainset = (X_train,y_train)\n",
        "model.fit_generator(trainset,steps_per_epoch=9,epochs=5)\n",
        "model.save_weights(\"model.h5\")\n",
        "\n",
        "testSet =  (X_test,y_test)\n",
        "alpha   = 0.3\n",
        "model.load_weights(\"model.h5\")\n",
        "if not os.path.exists(\"./results\"): os.mkdir(\"./results\")\n",
        "\n",
        "for idx, (img, mask) in enumerate(testSet):\n",
        "    oring_img = img[0]\n",
        "    pred_mask = model.predict(img)[0]\n",
        "    pred_mask[pred_mask > 0.5] = 1\n",
        "    pred_mask[pred_mask <= 0.5] = 0\n",
        "    img = cv2.cvtColor(img[0], cv2.COLOR_GRAY2RGB)\n",
        "    H, W, C = img.shape\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            if pred_mask[i][j][0] <= 0.5:\n",
        "                img[i][j] = (1-alpha)*img[i][j]*255 + alpha*np.array([0, 0, 255])\n",
        "            else:\n",
        "                img[i][j] = img[i][j]*255\n",
        "    image_accuracy = np.mean(mask == pred_mask)\n",
        "    image_path = \"/content/results/pred_\"+str(idx)+\".png\"\n",
        "    print(\"=> accuracy: %.4f, saving %s\" %(image_accuracy, image_path))\n",
        "    cv2.imwrite(image_path, img)\n",
        "    cv2.imwrite(\"/content/results/origin_%d.png\" %idx, oring_img*255)\n",
        "    if idx == 29: break"
      ],
      "metadata": {
        "id": "vSxu3A3Xb-fT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}