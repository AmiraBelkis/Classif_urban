{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Script.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmiraBelkis/Classif_urban/blob/Exmple2/Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet module"
      ],
      "metadata": {
        "id": "qahFfuTvWn3v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q12lIgW2T1pf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, Input, MaxPooling2D, Dropout, concatenate, UpSampling2D\n",
        "\n",
        "\n",
        "def Unet(num_class, image_size):\n",
        "\n",
        "    inputs = Input(shape=[image_size, image_size, 1])\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same')(conv9)\n",
        "    conv10 = Conv2D(num_class, 1, activation = 'sigmoid')(conv9)\n",
        "    model = Model(inputs = inputs, outputs = conv10)\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "9uaznsduWyN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "#from Unet import Unet\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "8CNJgIJhaGcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def DataGenerator(file_path, batch_size):\n",
        "    \"\"\"\n",
        "    generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen\n",
        "    to ensure the transformation for image and mask is the same\n",
        "    \"\"\"\n",
        "    aug_dict = dict(rotation_range=0.2,\n",
        "                        width_shift_range=0.05,\n",
        "                        height_shift_range=0.05,\n",
        "                        shear_range=0.05,\n",
        "                        zoom_range=0.05,\n",
        "                        horizontal_flip=True,\n",
        "                        fill_mode='nearest')\n",
        "    aug_dict = dict(horizontal_flip=True,\n",
        "                        fill_mode='nearest')\n",
        "\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        file_path,\n",
        "        classes=[\"images\"],\n",
        "        color_mode = \"grayscale\",\n",
        "        target_size = (256, 256),\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size, seed=1)\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        file_path,\n",
        "        classes=[\"labels\"],\n",
        "        color_mode = \"grayscale\",\n",
        "        target_size = (256, 256),\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size, seed=1)\n",
        "\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img,mask) in train_generator:\n",
        "        img = img / 255.\n",
        "        mask = mask / 255.\n",
        "        mask[mask > 0.5] = 1\n",
        "        mask[mask <= 0.5] = 0\n",
        "        yield (img,mask)\n",
        "trainset = DataGenerator(\"/content/train\", batch_size=2)\n",
        "print(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL2wyT0xaEho",
        "outputId": "c34812d5-6942-43db-e05b-0e9354ea2e2c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object DataGenerator at 0x7fdd1c91d7d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Unet(1, image_size=256)\n",
        "trainset = DataGenerator(\"membrane/train\", batch_size=2)\n",
        "model.fit_generator(trainset,steps_per_epoch=5000,epochs=5)\n",
        "model.save_weights(\"model.h5\")\n",
        "\n",
        "testSet = DataGenerator(\"membrane/test\", batch_size=1)\n",
        "alpha   = 0.3\n",
        "model.load_weights(\"model.h5\")\n",
        "if not os.path.exists(\"./results\"): os.mkdir(\"./results\")\n",
        "\n",
        "for idx, (img, mask) in enumerate(testSet):\n",
        "    oring_img = img[0]\n",
        "    pred_mask = model.predict(img)[0]\n",
        "    pred_mask[pred_mask > 0.5] = 1\n",
        "    pred_mask[pred_mask <= 0.5] = 0\n",
        "    img = cv2.cvtColor(img[0], cv2.COLOR_GRAY2RGB)\n",
        "    H, W, C = img.shape\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            if pred_mask[i][j][0] <= 0.5:\n",
        "                img[i][j] = (1-alpha)*img[i][j]*255 + alpha*np.array([0, 0, 255])\n",
        "            else:\n",
        "                img[i][j] = img[i][j]*255\n",
        "    image_accuracy = np.mean(mask == pred_mask)\n",
        "    image_path = \"./results/pred_\"+str(idx)+\".png\"\n",
        "    print(\"=> accuracy: %.4f, saving %s\" %(image_accuracy, image_path))\n",
        "    cv2.imwrite(image_path, img)\n",
        "    cv2.imwrite(\"./results/origin_%d.png\" %idx, oring_img*255)\n",
        "    if idx == 29: break"
      ],
      "metadata": {
        "id": "vhYkMJ-WW5zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "os.chdir('/content/train/images')\n",
        "os.chdir('/content/train/masks')\n",
        "filelist_trainx   = os.listdir('/content/train/images')\n",
        "filelist_trainy = os.listdir('/content/train/masks')\n",
        "print(filelist_trainx)\n",
        "print(filelist_trainy)\n",
        "masks = []\n",
        "imgs = []\n",
        "for filename in filelist_trainx:\n",
        "  imgs.append(filename)\n",
        "for filename in filelist_trainy:\n",
        "  masks.append(filename)\n",
        "\n",
        "imgs.sort()\n",
        "masks.sort()\n",
        "print(imgs)\n",
        "print(masks)"
      ],
      "metadata": {
        "id": "btI_-CTCegUo",
        "outputId": "75b4c04e-a743-4967-8e9b-d909fc7f5f9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['image_part_001.jpg', 'image_part_002.jpg', 'image_part_007.jpg', 'image_part_004.jpg', 'image_part_005.jpg', 'image_part_009.jpg', 'image_part_006.jpg', 'image_part_008.jpg', 'image_part_003.jpg']\n",
            "['image_part_001.png', 'image_part_008.png', 'image_part_003.png', 'image_part_006.png', 'image_part_005.png', 'image_part_002.png', 'image_part_004.png', 'image_part_009.png', 'image_part_007.png']\n",
            "['image_part_001.jpg', 'image_part_002.jpg', 'image_part_003.jpg', 'image_part_004.jpg', 'image_part_005.jpg', 'image_part_006.jpg', 'image_part_007.jpg', 'image_part_008.jpg', 'image_part_009.jpg']\n",
            "['image_part_001.png', 'image_part_002.png', 'image_part_003.png', 'image_part_004.png', 'image_part_005.png', 'image_part_006.png', 'image_part_007.png', 'image_part_008.png', 'image_part_009.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.zeros((1000, 28,28), dtype=np.float32)\n",
        "X = np.zeros((1000,224, 224, 1), dtype=np.float32)\n",
        "n = 0\n",
        "for file in imgs:\n",
        "  print(file)\n",
        "  #index = img.index(file)\n",
        "  dir_img = os.path.join('/content/train/images', file)\n",
        "  img = Image.open(dir_img)\n",
        "  img = img.resize((224, 224))\n",
        "  img = np.reshape(img.convert('L'), (224,224,1)) \n",
        "  X[n] = img\n",
        "  n = n+1\n",
        "for mask in masks:\n",
        "  #mask = masks[index]\n",
        "  dir_mask = os.path.join('/content/train/masks', mask)\n",
        "  mask_img = cv2.imread(dir_mask)\n",
        "  mask_img = (mask!=2)*1.0  \n",
        "  mask_img = cv2.resize(mask_img, (28, 28))\n",
        "  mask_img = 1.0*(masks[:,:,0]>0.2)\n",
        "  y[n] = mask\n",
        "  n = n+1"
      ],
      "metadata": {
        "id": "uACsfbbPiN-m",
        "outputId": "c7ea63b2-1f48-435e-caec-276a4e8089bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_part_001.jpg\n",
            "image_part_002.jpg\n",
            "image_part_003.jpg\n",
            "image_part_004.jpg\n",
            "image_part_005.jpg\n",
            "image_part_006.jpg\n",
            "image_part_007.jpg\n",
            "image_part_008.jpg\n",
            "image_part_009.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c04c166e1030>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mmask_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mmask_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mmask_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Unet(1, image_size=256)\n",
        "trainset = (train_x,train_y)\n",
        "model.fit_generator(trainset,steps_per_epoch=5000,epochs=5)\n",
        "model.save_weights(\"model.h5\")\n",
        "\n",
        "testSet = DataGenerator(\"/content/test\", batch_size=1)\n",
        "alpha   = 0.3\n",
        "model.load_weights(\"model.h5\")\n",
        "#if not os.path.exists(\"./results\"): os.mkdir(\"./results\")\n",
        "\n",
        "for idx, (img, mask) in enumerate(testSet):\n",
        "    oring_img = img[0]\n",
        "    pred_mask = model.predict(img)[0]\n",
        "    pred_mask[pred_mask > 0.5] = 1\n",
        "    pred_mask[pred_mask <= 0.5] = 0\n",
        "    img = cv2.cvtColor(img[0], cv2.COLOR_GRAY2RGB)\n",
        "    H, W, C = img.shape\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            if pred_mask[i][j][0] <= 0.5:\n",
        "                img[i][j] = (1-alpha)*img[i][j]*255 + alpha*np.array([0, 0, 255])\n",
        "            else:\n",
        "                img[i][j] = img[i][j]*255\n",
        "    image_accuracy = np.mean(mask == pred_mask)\n",
        "    image_path = \"/content/results/pred_\"+str(idx)+\".png\"\n",
        "    print(\"=> accuracy: %.4f, saving %s\" %(image_accuracy, image_path))\n",
        "    cv2.imwrite(image_path, img)\n",
        "    cv2.imwrite(\"/content/results/origin_%d.png\" %idx, oring_img*255)\n",
        "    if idx == 29: break"
      ],
      "metadata": {
        "id": "vSxu3A3Xb-fT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}