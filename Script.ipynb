{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Script.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmiraBelkis/Classif_urban/blob/Exmple2/Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet module"
      ],
      "metadata": {
        "id": "qahFfuTvWn3v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q12lIgW2T1pf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, Input, MaxPooling2D, Dropout, concatenate, UpSampling2D\n",
        "\n",
        "\n",
        "def Unet(num_class, image_size):\n",
        "\n",
        "    inputs = Input(shape=[image_size, image_size, 1])\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same')(conv9)\n",
        "    conv10 = Conv2D(num_class, 1, activation = 'sigmoid')(conv9)\n",
        "    model = Model(inputs = inputs, outputs = conv10)\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "9uaznsduWyN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "#from Unet import Unet\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "8CNJgIJhaGcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def DataGenerator(file_path, batch_size):\n",
        "    \"\"\"\n",
        "    generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen\n",
        "    to ensure the transformation for image and mask is the same\n",
        "    \"\"\"\n",
        "    aug_dict = dict(rotation_range=0.2,\n",
        "                        width_shift_range=0.05,\n",
        "                        height_shift_range=0.05,\n",
        "                        shear_range=0.05,\n",
        "                        zoom_range=0.05,\n",
        "                        horizontal_flip=True,\n",
        "                        fill_mode='nearest')\n",
        "    aug_dict = dict(horizontal_flip=True,\n",
        "                        fill_mode='nearest')\n",
        "\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        file_path,\n",
        "        classes=[\"images\"],\n",
        "        color_mode = \"grayscale\",\n",
        "        target_size = (256, 256),\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size, seed=1)\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        file_path,\n",
        "        classes=[\"labels\"],\n",
        "        color_mode = \"grayscale\",\n",
        "        target_size = (256, 256),\n",
        "        class_mode = None,\n",
        "        batch_size = batch_size, seed=1)\n",
        "\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img,mask) in train_generator:\n",
        "        img = img / 255.\n",
        "        mask = mask / 255.\n",
        "        mask[mask > 0.5] = 1\n",
        "        mask[mask <= 0.5] = 0\n",
        "        yield (img,mask)\n",
        "trainset = DataGenerator(\"/content/train\", batch_size=2)\n",
        "print(trainset)"
      ],
      "metadata": {
        "id": "YL2wyT0xaEho",
        "outputId": "c34812d5-6942-43db-e05b-0e9354ea2e2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object DataGenerator at 0x7fdd1c91d7d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Unet(1, image_size=256)\n",
        "trainset = DataGenerator(\"membrane/train\", batch_size=2)\n",
        "model.fit_generator(trainset,steps_per_epoch=5000,epochs=5)\n",
        "model.save_weights(\"model.h5\")\n",
        "\n",
        "testSet = DataGenerator(\"membrane/test\", batch_size=1)\n",
        "alpha   = 0.3\n",
        "model.load_weights(\"model.h5\")\n",
        "if not os.path.exists(\"./results\"): os.mkdir(\"./results\")\n",
        "\n",
        "for idx, (img, mask) in enumerate(testSet):\n",
        "    oring_img = img[0]\n",
        "    pred_mask = model.predict(img)[0]\n",
        "    pred_mask[pred_mask > 0.5] = 1\n",
        "    pred_mask[pred_mask <= 0.5] = 0\n",
        "    img = cv2.cvtColor(img[0], cv2.COLOR_GRAY2RGB)\n",
        "    H, W, C = img.shape\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            if pred_mask[i][j][0] <= 0.5:\n",
        "                img[i][j] = (1-alpha)*img[i][j]*255 + alpha*np.array([0, 0, 255])\n",
        "            else:\n",
        "                img[i][j] = img[i][j]*255\n",
        "    image_accuracy = np.mean(mask == pred_mask)\n",
        "    image_path = \"./results/pred_\"+str(idx)+\".png\"\n",
        "    print(\"=> accuracy: %.4f, saving %s\" %(image_accuracy, image_path))\n",
        "    cv2.imwrite(image_path, img)\n",
        "    cv2.imwrite(\"./results/origin_%d.png\" %idx, oring_img*255)\n",
        "    if idx == 29: break"
      ],
      "metadata": {
        "id": "vhYkMJ-WW5zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Unet(1, image_size=256)\n",
        "trainset = DataGenerator(\"/content/train\", batch_size=2)\n",
        "model.fit_generator(trainset,steps_per_epoch=5000,epochs=5)\n",
        "model.save_weights(\"model.h5\")\n",
        "\n",
        "testSet = DataGenerator(\"/content/test\", batch_size=1)\n",
        "alpha   = 0.3\n",
        "model.load_weights(\"model.h5\")\n",
        "#if not os.path.exists(\"./results\"): os.mkdir(\"./results\")\n",
        "\n",
        "for idx, (img, mask) in enumerate(testSet):\n",
        "    oring_img = img[0]\n",
        "    pred_mask = model.predict(img)[0]\n",
        "    pred_mask[pred_mask > 0.5] = 1\n",
        "    pred_mask[pred_mask <= 0.5] = 0\n",
        "    img = cv2.cvtColor(img[0], cv2.COLOR_GRAY2RGB)\n",
        "    H, W, C = img.shape\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            if pred_mask[i][j][0] <= 0.5:\n",
        "                img[i][j] = (1-alpha)*img[i][j]*255 + alpha*np.array([0, 0, 255])\n",
        "            else:\n",
        "                img[i][j] = img[i][j]*255\n",
        "    image_accuracy = np.mean(mask == pred_mask)\n",
        "    image_path = \"/content/results/pred_\"+str(idx)+\".png\"\n",
        "    print(\"=> accuracy: %.4f, saving %s\" %(image_accuracy, image_path))\n",
        "    cv2.imwrite(image_path, img)\n",
        "    cv2.imwrite(\"/content/results/origin_%d.png\" %idx, oring_img*255)\n",
        "    if idx == 29: break"
      ],
      "metadata": {
        "id": "vSxu3A3Xb-fT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}